From: Alaa Hleihel <alaa@mellanox.com>
Subject: [PATCH] BACKPORT: qib

Signed-off-by: Alaa Hleihel <alaa@mellanox.com>
---
 drivers/infiniband/hw/qib/qib.h           |   7 ++
 drivers/infiniband/hw/qib/qib_file_ops.c  |  27 +++++
 drivers/infiniband/hw/qib/qib_fs.c        |  44 ++++++++
 drivers/infiniband/hw/qib/qib_iba6120.c   |   6 ++
 drivers/infiniband/hw/qib/qib_iba7220.c   |   6 ++
 drivers/infiniband/hw/qib/qib_iba7322.c   |   6 ++
 drivers/infiniband/hw/qib/qib_init.c      |  36 ++++++-
 drivers/infiniband/hw/qib/qib_pcie.c      | 165 ++++++++++++++++++++++++++++++
 drivers/infiniband/hw/qib/qib_sysfs.c     |  12 +++
 drivers/infiniband/hw/qib/qib_wc_x86_64.c |  33 ++++++
 10 files changed, 340 insertions(+), 2 deletions(-)

--- a/drivers/infiniband/hw/qib/qib.h
+++ b/drivers/infiniband/hw/qib/qib.h
@@ -88,7 +88,11 @@ struct qlogic_ib_stats {
 };
 
 extern struct qlogic_ib_stats qib_stats;
+#ifdef CONFIG_COMPAT_IS_CONST_PCI_ERROR_HANDLERS
 extern const struct pci_error_handlers qib_pci_err_handler;
+#else
+extern struct pci_error_handlers qib_pci_err_handler;
+#endif
 
 #define QIB_CHIP_SWVERSION QIB_CHIP_VERS_MAJ
 /*
@@ -1142,6 +1146,9 @@ extern struct qib_devdata *qib_lookup(in
 extern u32 qib_cpulist_count;
 extern unsigned long *qib_cpulist;
 
+#ifndef HAVE_ARCH_PHYS_WC_ADD
+extern unsigned qib_wc_pat;
+#endif
 extern unsigned qib_cc_table_size;
 int qib_init(struct qib_devdata *, int);
 int init_chip_wc_pat(struct qib_devdata *dd, u32);
--- a/drivers/infiniband/hw/qib/qib_file_ops.c
+++ b/drivers/infiniband/hw/qib/qib_file_ops.c
@@ -44,6 +44,9 @@
 #include <asm/pgtable.h>
 #include <linux/delay.h>
 #include <linux/export.h>
+#ifndef HAVE_AIO_WRITE
+#include <linux/uio.h>
+#endif
 
 #include <rdma/ib.h>
 
@@ -57,15 +60,23 @@
 static int qib_open(struct inode *, struct file *);
 static int qib_close(struct inode *, struct file *);
 static ssize_t qib_write(struct file *, const char __user *, size_t, loff_t *);
+#ifdef HAVE_AIO_WRITE
 static ssize_t qib_aio_write(struct kiocb *, const struct iovec *,
 			     unsigned long, loff_t);
+#else
+static ssize_t qib_write_iter(struct kiocb *, struct iov_iter *);
+#endif
 static unsigned int qib_poll(struct file *, struct poll_table_struct *);
 static int qib_mmapf(struct file *, struct vm_area_struct *);
 
 static const struct file_operations qib_file_ops = {
 	.owner = THIS_MODULE,
 	.write = qib_write,
+#ifdef HAVE_AIO_WRITE
 	.aio_write = qib_aio_write,
+#else
+	.write_iter = qib_write_iter,
+#endif
 	.open = qib_open,
 	.release = qib_close,
 	.poll = qib_poll,
@@ -829,8 +840,12 @@ static int mmap_piobufs(struct vm_area_s
 	vma->vm_flags &= ~VM_MAYREAD;
 	vma->vm_flags |= VM_DONTCOPY | VM_DONTEXPAND;
 
+#ifdef HAVE_ARCH_PHYS_WC_ADD
 	/* We used PAT if wc_cookie == 0 */
 	if (!dd->wc_cookie)
+#else
+	if (qib_wc_pat)
+#endif
 		vma->vm_page_prot = pgprot_writecombine(vma->vm_page_prot);
 
 	ret = io_remap_pfn_range(vma, vma->vm_start, phys >> PAGE_SHIFT,
@@ -2248,17 +2263,29 @@ bail:
 	return ret;
 }
 
+#ifdef HAVE_AIO_WRITE
 static ssize_t qib_aio_write(struct kiocb *iocb, const struct iovec *iov,
 			     unsigned long dim, loff_t off)
+#else
+static ssize_t qib_write_iter(struct kiocb *iocb, struct iov_iter *from)
+#endif
 {
 	struct qib_filedata *fp = iocb->ki_filp->private_data;
 	struct qib_ctxtdata *rcd = ctxt_fp(iocb->ki_filp);
 	struct qib_user_sdma_queue *pq = fp->pq;
 
+#ifdef HAVE_AIO_WRITE
 	if (!dim || !pq)
+#else
+	if (!iter_is_iovec(from) || !from->nr_segs || !pq)
+#endif
 		return -EINVAL;
 
+#ifdef HAVE_AIO_WRITE
 	return qib_user_sdma_writev(rcd, pq, iov, dim);
+#else
+	return qib_user_sdma_writev(rcd, pq, from->iov, from->nr_segs);
+#endif
 }
 
 static struct class *qib_class;
--- a/drivers/infiniband/hw/qib/qib_fs.c
+++ b/drivers/infiniband/hw/qib/qib_fs.c
@@ -45,7 +45,11 @@
 
 static struct super_block *qib_super;
 
+#ifdef CONFIG_COMPAT_IS_FILE_INODE
 #define private2dd(file) (file_inode(file)->i_private)
+#else
+#define private2dd(file) ((file)->f_dentry->d_inode->i_private)
+#endif
 
 static int qibfs_mknod(struct inode *dir, struct dentry *dentry,
 		       umode_t mode, const struct file_operations *fops,
@@ -59,7 +63,9 @@ static int qibfs_mknod(struct inode *dir
 		goto bail;
 	}
 
+#ifdef HAVE_GET_NEXT_INO
 	inode->i_ino = get_next_ino();
+#endif
 	inode->i_mode = mode;
 	inode->i_uid = GLOBAL_ROOT_UID;
 	inode->i_gid = GLOBAL_ROOT_GID;
@@ -89,14 +95,22 @@ static int create_file(const char *name,
 {
 	int error;
 
+#ifdef HAVE_INODE_LOCK
+	inode_lock(d_inode(parent));
+#else
 	mutex_lock(&parent->d_inode->i_mutex);
+#endif
 	*dentry = lookup_one_len(name, parent, strlen(name));
 	if (!IS_ERR(*dentry))
 		error = qibfs_mknod(parent->d_inode, *dentry,
 				    mode, fops, data);
 	else
 		error = PTR_ERR(*dentry);
+#ifdef HAVE_INODE_LOCK
+	inode_unlock(d_inode(parent));
+#else
 	mutex_unlock(&parent->d_inode->i_mutex);
+#endif
 
 	return error;
 }
@@ -481,7 +495,11 @@ static int remove_device_files(struct su
 	int ret, i;
 
 	root = dget(sb->s_root);
+#ifdef HAVE_INODE_LOCK
+	inode_lock(d_inode(root));
+#else
 	mutex_lock(&root->d_inode->i_mutex);
+#endif
 	snprintf(unit, sizeof unit, "%u", dd->unit);
 	dir = lookup_one_len(unit, root, strlen(unit));
 
@@ -491,7 +509,11 @@ static int remove_device_files(struct su
 		goto bail;
 	}
 
+#ifdef HAVE_INODE_LOCK
+	inode_lock(d_inode(dir));
+#else
 	mutex_lock(&dir->d_inode->i_mutex);
+#endif
 	remove_file(dir, "counters");
 	remove_file(dir, "counter_names");
 	remove_file(dir, "portcounter_names");
@@ -506,13 +528,21 @@ static int remove_device_files(struct su
 		}
 	}
 	remove_file(dir, "flash");
+#ifdef HAVE_INODE_LOCK
+	inode_unlock(d_inode(dir));
+#else
 	mutex_unlock(&dir->d_inode->i_mutex);
+#endif
 	ret = simple_rmdir(root->d_inode, dir);
 	d_delete(dir);
 	dput(dir);
 
 bail:
+#ifdef HAVE_INODE_LOCK
+	inode_unlock(d_inode(root));
+#else
 	mutex_unlock(&root->d_inode->i_mutex);
+#endif
 	dput(root);
 	return ret;
 }
@@ -556,6 +586,7 @@ bail:
 	return ret;
 }
 
+#ifdef HAVE_FILE_SYSTEM_TYPE_MOUNT
 static struct dentry *qibfs_mount(struct file_system_type *fs_type, int flags,
 			const char *dev_name, void *data)
 {
@@ -563,6 +594,15 @@ static struct dentry *qibfs_mount(struct
 	ret = mount_single(fs_type, flags, data, qibfs_fill_super);
 	if (!IS_ERR(ret))
 		qib_super = ret->d_sb;
+#else
+static int qibfs_get_sb(struct file_system_type *fs_type, int flags,
+			const char *dev_name, void *data, struct vfsmount *mnt)
+{
+	int ret = get_sb_single(fs_type, flags, data,
+					qibfs_fill_super, mnt);
+	if (ret >= 0)
+		qib_super = mnt->mnt_sb;
+#endif
 	return ret;
 }
 
@@ -604,7 +644,11 @@ int qibfs_remove(struct qib_devdata *dd)
 static struct file_system_type qibfs_fs_type = {
 	.owner =        THIS_MODULE,
 	.name =         "ipathfs",
+#ifdef HAVE_FILE_SYSTEM_TYPE_MOUNT
 	.mount =        qibfs_mount,
+#else
+	.get_sb =        qibfs_get_sb,
+#endif
 	.kill_sb =      qibfs_kill_super,
 };
 MODULE_ALIAS_FS("ipathfs");
--- a/drivers/infiniband/hw/qib/qib_iba6120.c
+++ b/drivers/infiniband/hw/qib/qib_iba6120.c
@@ -3312,9 +3312,15 @@ static int init_6120_variables(struct qi
 	qib_6120_config_ctxts(dd);
 	qib_set_ctxtcnt(dd);
 
+#ifndef HAVE_ARCH_PHYS_WC_ADD
+	if (qib_wc_pat) {
+#endif
 	ret = init_chip_wc_pat(dd, 0);
 	if (ret)
 		goto bail;
+#ifndef HAVE_ARCH_PHYS_WC_ADD
+	}
+#endif
 	set_6120_baseaddrs(dd); /* set chip access pointers now */
 
 	ret = 0;
--- a/drivers/infiniband/hw/qib/qib_iba7220.c
+++ b/drivers/infiniband/hw/qib/qib_iba7220.c
@@ -4126,9 +4126,15 @@ static int qib_init_7220_variables(struc
 	qib_7220_config_ctxts(dd);
 	qib_set_ctxtcnt(dd);  /* needed for PAT setup */
 
+#ifndef HAVE_ARCH_PHYS_WC_ADD
+	if (qib_wc_pat) {
+#endif
 	ret = init_chip_wc_pat(dd, 0);
 	if (ret)
 		goto bail;
+#ifndef HAVE_ARCH_PHYS_WC_ADD
+	}
+#endif
 	set_7220_baseaddrs(dd); /* set chip access pointers now */
 
 	ret = 0;
--- a/drivers/infiniband/hw/qib/qib_iba7322.c
+++ b/drivers/infiniband/hw/qib/qib_iba7322.c
@@ -6661,6 +6661,9 @@ static int qib_init_7322_variables(struc
 	qib_7322_config_ctxts(dd);
 	qib_set_ctxtcnt(dd);
 
+#ifndef HAVE_ARCH_PHYS_WC_ADD
+	if (qib_wc_pat) {
+#endif
 	/*
 	 * We do not set WC on the VL15 buffers to avoid
 	 * a rare problem with unaligned writes from
@@ -6680,6 +6683,9 @@ static int qib_init_7322_variables(struc
 	if (!dd->piovl15base) {
 		ret = -ENOMEM;
 		goto bail;
+#ifndef HAVE_ARCH_PHYS_WC_ADD
+	}
+#endif
 	}
 
 	qib_7322_set_baseaddrs(dd); /* set chip access pointers now */
--- a/drivers/infiniband/hw/qib/qib_init.c
+++ b/drivers/infiniband/hw/qib/qib_init.c
@@ -91,6 +91,17 @@ MODULE_PARM_DESC(krcvqs, "number of kern
 unsigned qib_cc_table_size;
 module_param_named(cc_table_size, qib_cc_table_size, uint, S_IRUGO);
 MODULE_PARM_DESC(cc_table_size, "Congestion control table entries 0 (CCA disabled - default), min = 128, max = 1984");
+#ifndef HAVE_ARCH_PHYS_WC_ADD
+/*
+ * qib_wc_pat parameter:
+ *      0 is WC via MTRR
+ *      1 is WC via PAT
+ *      If PAT initialization fails, code reverts back to MTRR
+ */
+unsigned qib_wc_pat = 1; /* default (1) is to use PAT, not MTRR */
+module_param_named(wc_pat, qib_wc_pat, uint, S_IRUGO);
+MODULE_PARM_DESC(wc_pat, "enable write-combining via PAT mechanism");
+#endif
 
 static void verify_interrupt(unsigned long);
 
@@ -1127,17 +1138,25 @@ struct qib_devdata *qib_alloc_devdata(st
 
 	INIT_LIST_HEAD(&dd->list);
 
+#ifdef HAVE_IDR_ALLOC
 	idr_preload(GFP_KERNEL);
+#endif
 	spin_lock_irqsave(&qib_devs_lock, flags);
-
+#ifndef HAVE_IDR_ALLOC
+	ret = idr_get_new(&qib_unit_table, dd, &dd->unit);
+	if (ret >= 0)
+		list_add(&dd->list, &qib_dev_list);
+#else
 	ret = idr_alloc(&qib_unit_table, dd, 0, 0, GFP_NOWAIT);
 	if (ret >= 0) {
 		dd->unit = ret;
 		list_add(&dd->list, &qib_dev_list);
 	}
-
+#endif
 	spin_unlock_irqrestore(&qib_devs_lock, flags);
+#ifdef HAVE_IDR_ALLOC
 	idr_preload_end();
+#endif
 
 	if (ret < 0) {
 		qib_early_err(&pdev->dev,
@@ -1366,6 +1385,9 @@ static void cleanup_device_data(struct q
 		spin_unlock(&dd->pport[pidx].cc_shadow_lock);
 	}
 
+#ifndef HAVE_ARCH_PHYS_WC_ADD
+	if (!qib_wc_pat)
+#endif
 	qib_disable_wc(dd);
 
 	if (dd->pioavailregs_dma) {
@@ -1535,6 +1557,9 @@ static int qib_init_one(struct pci_dev *
 		goto bail;
 	}
 
+#ifndef HAVE_ARCH_PHYS_WC_ADD
+	if (!qib_wc_pat) {
+#endif
 	ret = qib_enable_wc(dd);
 	if (ret) {
 		qib_dev_err(dd,
@@ -1542,6 +1567,9 @@ static int qib_init_one(struct pci_dev *
 			-ret);
 		ret = 0;
 	}
+#ifndef HAVE_ARCH_PHYS_WC_ADD
+	}
+#endif
 
 	qib_verify_pioperf(dd);
 bail:
@@ -1678,7 +1706,11 @@ int qib_setup_eagerbufs(struct qib_ctxtd
 	 * heavy filesystem activity makes these fail, and we can
 	 * use compound pages.
 	 */
+#ifdef __GFP_WAIT
 	gfp_flags = __GFP_WAIT | __GFP_IO | __GFP_COMP;
+#else
+	gfp_flags = __GFP_RECLAIM | __GFP_IO | __GFP_COMP;
+#endif
 
 	egrcnt = rcd->rcvegrcnt;
 	egroff = rcd->rcvegr_tid_base;
--- a/drivers/infiniband/hw/qib/qib_pcie.c
+++ b/drivers/infiniband/hw/qib/qib_pcie.c
@@ -191,26 +191,43 @@ static void qib_msix_setup(struct qib_de
 			   struct qib_msix_entry *qib_msix_entry)
 {
 	int ret;
+#if defined(HAVE_PCI_ENABLE_MSIX_RANGE) && defined(HAVE_PCI_MSIX_VEC_COUNT)
 	int nvec = *msixcnt;
+#else
+	u32 tabsize = 0;
+	u16 msix_flags;
+#endif
 	struct msix_entry *msix_entry;
 	int i;
 
+#if defined(HAVE_PCI_ENABLE_MSIX_RANGE) && defined(HAVE_PCI_MSIX_VEC_COUNT)
 	ret = pci_msix_vec_count(dd->pcidev);
 	if (ret < 0)
 		goto do_intx;
 
 	nvec = min(nvec, ret);
+#endif
 
 	/* We can't pass qib_msix_entry array to qib_msix_setup
 	 * so use a dummy msix_entry array and copy the allocated
 	 * irq back to the qib_msix_entry array. */
+#if defined(HAVE_PCI_ENABLE_MSIX_RANGE) && defined(HAVE_PCI_MSIX_VEC_COUNT)
 	msix_entry = kmalloc(nvec * sizeof(*msix_entry), GFP_KERNEL);
 	if (!msix_entry)
 		goto do_intx;
 
 	for (i = 0; i < nvec; i++)
+#else
+	msix_entry = kmalloc(*msixcnt * sizeof(*msix_entry), GFP_KERNEL);
+	if (!msix_entry) {
+		ret = -ENOMEM;
+		goto do_intx;
+	}
+	for (i = 0; i < *msixcnt; i++)
+#endif
 		msix_entry[i] = qib_msix_entry[i].msix;
 
+#if defined(HAVE_PCI_ENABLE_MSIX_RANGE) && defined(HAVE_PCI_MSIX_VEC_COUNT)
 	ret = pci_enable_msix_range(dd->pcidev, msix_entry, 1, nvec);
 	if (ret < 0)
 		goto free_msix_entry;
@@ -218,9 +235,29 @@ static void qib_msix_setup(struct qib_de
 		nvec = ret;
 
 	for (i = 0; i < nvec; i++)
+#else
+	pci_read_config_word(dd->pcidev, pos + PCI_MSIX_FLAGS, &msix_flags);
+	tabsize = 1 + (msix_flags & PCI_MSIX_FLAGS_QSIZE);
+	if (tabsize > *msixcnt)
+		tabsize = *msixcnt;
+	ret = pci_enable_msix(dd->pcidev, msix_entry, tabsize);
+	if (ret > 0) {
+		tabsize = ret;
+		ret = pci_enable_msix(dd->pcidev, msix_entry, tabsize);
+	}
+do_intx:
+	if (ret) {
+		qib_dev_err(dd,
+				"pci_enable_msix %d vectors failed: %d, falling back to INTx\n",
+				tabsize, ret);
+		tabsize = 0;
+	}
+	for (i = 0; i < tabsize; i++)
+#endif
 		qib_msix_entry[i].msix = msix_entry[i];
 
 	kfree(msix_entry);
+#if defined(HAVE_PCI_ENABLE_MSIX_RANGE) && defined(HAVE_PCI_MSIX_VEC_COUNT)
 	*msixcnt = nvec;
 	return;
 
@@ -232,6 +269,12 @@ do_intx:
 			"falling back to INTx\n", nvec, ret);
 	*msixcnt = 0;
 	qib_enable_intx(dd->pcidev);
+#else
+	*msixcnt = tabsize;
+
+	if (ret)
+		qib_enable_intx(dd->pcidev);
+#endif
 }
 
 /**
@@ -278,12 +321,20 @@ int qib_pcie_params(struct qib_devdata *
 		goto bail;
 	}
 
+#ifdef HAVE_MSIX_CAP
 	pos = dd->pcidev->msix_cap;
+#else
+	pos = pci_find_capability(dd->pcidev, PCI_CAP_ID_MSIX);
+#endif
 	if (nent && *nent && pos) {
 		qib_msix_setup(dd, pos, nent, entry);
 		ret = 0; /* did it, either MSIx or INTx */
 	} else {
+#ifdef HAVE_MSIX_CAP
 		pos = dd->pcidev->msi_cap;
+#else
+		pos = pci_find_capability(dd->pcidev, PCI_CAP_ID_MSI);
+#endif
 		if (pos)
 			ret = qib_msi_setup(dd, pos);
 		else
@@ -352,7 +403,11 @@ int qib_reinit_intr(struct qib_devdata *
 	if (!dd->msi_lo)
 		goto bail;
 
+#ifdef HAVE_MSIX_CAP
 	pos = dd->pcidev->msi_cap;
+#else
+	pos = pci_find_capability(dd->pcidev, PCI_CAP_ID_MSI);
+#endif
 	if (!pos) {
 		qib_dev_err(dd,
 			"Can't find MSI capability, can't restore MSI settings\n");
@@ -421,7 +476,11 @@ void qib_enable_intx(struct pci_dev *pde
 	if (new != cw)
 		pci_write_config_word(pdev, PCI_COMMAND, new);
 
+#ifdef HAVE_MSIX_CAP
 	pos = pdev->msi_cap;
+#else
+	pos = pci_find_capability(pdev, PCI_CAP_ID_MSI);
+#endif
 	if (pos) {
 		/* then turn off MSI */
 		pci_read_config_word(pdev, pos + PCI_MSI_FLAGS, &cw);
@@ -429,7 +488,11 @@ void qib_enable_intx(struct pci_dev *pde
 		if (new != cw)
 			pci_write_config_word(pdev, pos + PCI_MSI_FLAGS, new);
 	}
+#ifdef HAVE_MSIX_CAP
 	pos = pdev->msix_cap;
+#else
+	pos = pci_find_capability(pdev, PCI_CAP_ID_MSIX);
+#endif
 	if (pos) {
 		/* then turn off MSIx */
 		pci_read_config_word(pdev, pos + PCI_MSIX_FLAGS, &cw);
@@ -471,6 +534,32 @@ void qib_pcie_reenable(struct qib_devdat
 			"pci_enable_device failed after reset: %d\n", r);
 }
 
+#ifndef HAVE_PCI_DEV_PCIE_MPSS
+/* code to adjust PCIe capabilities. */
+
+static int fld2val(int wd, int mask)
+{
+	int lsbmask;
+
+	if (!mask)
+		return 0;
+	wd &= mask;
+	lsbmask = mask ^ (mask & (mask - 1));
+	wd /= lsbmask;
+	return wd;
+}
+
+static int val2fld(int wd, int mask)
+{
+	int lsbmask;
+
+	if (!mask)
+		return 0;
+	lsbmask = mask ^ (mask & (mask - 1));
+	wd *= lsbmask;
+	return wd;
+}
+#endif
 
 static int qib_pcie_coalesce;
 module_param_named(pcie_coalesce, qib_pcie_coalesce, int, S_IRUGO);
@@ -553,6 +642,7 @@ MODULE_PARM_DESC(pcie_caps, "Max PCIe tu
 static void qib_tune_pcie_caps(struct qib_devdata *dd)
 {
 	struct pci_dev *parent;
+#ifdef HAVE_PCI_DEV_PCIE_MPSS
 	u16 rc_mpss, rc_mps, ep_mpss, ep_mps;
 	u16 rc_mrrs, ep_mrrs, max_mrrs;
 
@@ -611,6 +701,77 @@ static void qib_tune_pcie_caps(struct qi
 		ep_mrrs = max_mrrs;
 		pcie_set_readrq(dd->pcidev, ep_mrrs);
 	}
+#else
+	u16 pcaps, pctl, ecaps, ectl;
+	int rc_sup, ep_sup;
+	int rc_cur, ep_cur;
+
+	/* Find out supported and configured values for parent (root) */
+	parent = dd->pcidev->bus->self;
+	if (parent->bus->parent) {
+		qib_devinfo(dd->pcidev, "Parent not root\n");
+		return;
+	}
+
+	if (!pci_is_pcie(parent) || !pci_is_pcie(dd->pcidev))
+		return;
+	pcie_capability_read_word(parent, PCI_EXP_DEVCAP, &pcaps);
+	pcie_capability_read_word(parent, PCI_EXP_DEVCTL, &pctl);
+	/* Find out supported and configured values for endpoint (us) */
+	pcie_capability_read_word(dd->pcidev, PCI_EXP_DEVCAP, &ecaps);
+	pcie_capability_read_word(dd->pcidev, PCI_EXP_DEVCTL, &ectl);
+
+	/* Find max payload supported by root, endpoint */
+	rc_sup = fld2val(pcaps, PCI_EXP_DEVCAP_PAYLOAD);
+	ep_sup = fld2val(ecaps, PCI_EXP_DEVCAP_PAYLOAD);
+	if (rc_sup > ep_sup)
+		rc_sup = ep_sup;
+
+	rc_cur = fld2val(pctl, PCI_EXP_DEVCTL_PAYLOAD);
+	ep_cur = fld2val(ectl, PCI_EXP_DEVCTL_PAYLOAD);
+
+	/* If Supported greater than limit in module param, limit it */
+	if (rc_sup > (qib_pcie_caps & 7))
+		rc_sup = qib_pcie_caps & 7;
+	/* If less than (allowed, supported), bump root payload */
+	if (rc_sup > rc_cur) {
+		rc_cur = rc_sup;
+		pctl = (pctl & ~PCI_EXP_DEVCTL_PAYLOAD) |
+			val2fld(rc_cur, PCI_EXP_DEVCTL_PAYLOAD);
+		pcie_capability_write_word(parent, PCI_EXP_DEVCTL, pctl);
+	}
+	/* If less than (allowed, supported), bump endpoint payload */
+	if (rc_sup > ep_cur) {
+		ep_cur = rc_sup;
+		ectl = (ectl & ~PCI_EXP_DEVCTL_PAYLOAD) |
+			val2fld(ep_cur, PCI_EXP_DEVCTL_PAYLOAD);
+		pcie_capability_write_word(dd->pcidev, PCI_EXP_DEVCTL, ectl);
+	}
+
+	/*
+	 * Now the Read Request size.
+	 * No field for max supported, but PCIe spec limits it to 4096,
+	 * which is code '5' (log2(4096) - 7)
+	 */
+	rc_sup = 5;
+	if (rc_sup > ((qib_pcie_caps >> 4) & 7))
+		rc_sup = (qib_pcie_caps >> 4) & 7;
+	rc_cur = fld2val(pctl, PCI_EXP_DEVCTL_READRQ);
+	ep_cur = fld2val(ectl, PCI_EXP_DEVCTL_READRQ);
+
+	if (rc_sup > rc_cur) {
+		rc_cur = rc_sup;
+		pctl = (pctl & ~PCI_EXP_DEVCTL_READRQ) |
+			val2fld(rc_cur, PCI_EXP_DEVCTL_READRQ);
+		pcie_capability_write_word(parent, PCI_EXP_DEVCTL, pctl);
+	}
+	if (rc_sup > ep_cur) {
+		ep_cur = rc_sup;
+		ectl = (ectl & ~PCI_EXP_DEVCTL_READRQ) |
+			val2fld(ep_cur, PCI_EXP_DEVCTL_READRQ);
+		pcie_capability_write_word(dd->pcidev, PCI_EXP_DEVCTL, ectl);
+	}
+#endif
 }
 /* End of PCIe capability tuning */
 
@@ -700,7 +861,11 @@ qib_pci_resume(struct pci_dev *pdev)
 	qib_init(dd, 1); /* same as re-init after reset */
 }
 
+#ifdef CONFIG_COMPAT_IS_CONST_PCI_ERROR_HANDLERS
 const struct pci_error_handlers qib_pci_err_handler = {
+#else
+struct pci_error_handlers qib_pci_err_handler = {
+#endif
 	.error_detected = qib_pci_error_detected,
 	.mmio_enabled = qib_pci_mmio_enabled,
 	.link_reset = qib_pci_link_reset,
--- a/drivers/infiniband/hw/qib/qib_sysfs.c
+++ b/drivers/infiniband/hw/qib/qib_sysfs.c
@@ -316,7 +316,11 @@ static ssize_t qib_portattr_store(struct
 }
 
 
+#ifdef CONFIG_COMPAT_IS_CONST_KOBJECT_SYSFS_OPS
 static const struct sysfs_ops qib_port_ops = {
+#else
+static struct sysfs_ops qib_port_ops = {
+#endif
 	.show = qib_portattr_show,
 	.store = qib_portattr_store,
 };
@@ -389,7 +393,11 @@ static ssize_t sl2vl_attr_show(struct ko
 	return sprintf(buf, "%u\n", qibp->sl_to_vl[sattr->sl]);
 }
 
+#ifdef CONFIG_COMPAT_IS_CONST_KOBJECT_SYSFS_OPS
 static const struct sysfs_ops qib_sl2vl_ops = {
+#else
+static struct sysfs_ops qib_sl2vl_ops = {
+#endif
 	.show = sl2vl_attr_show,
 };
 
@@ -479,7 +487,11 @@ static ssize_t diagc_attr_store(struct k
 	return size;
 }
 
+#ifdef CONFIG_COMPAT_IS_CONST_KOBJECT_SYSFS_OPS
 static const struct sysfs_ops qib_diagc_ops = {
+#else
+static struct sysfs_ops qib_diagc_ops = {
+#endif
 	.show = diagc_attr_show,
 	.store = diagc_attr_store,
 };
--- a/drivers/infiniband/hw/qib/qib_wc_x86_64.c
+++ b/drivers/infiniband/hw/qib/qib_wc_x86_64.c
@@ -115,9 +115,27 @@ int qib_enable_wc(struct qib_devdata *dd
 	}
 
 	if (!ret) {
+#ifdef HAVE_ARCH_PHYS_WC_ADD
 		dd->wc_cookie = arch_phys_wc_add(pioaddr, piolen);
 		if (dd->wc_cookie < 0)
 			ret = -EINVAL;
+#else
+		int cookie;
+
+		cookie = mtrr_add(pioaddr, piolen, MTRR_TYPE_WRCOMB, 0);
+		if (cookie < 0) {
+			{
+				qib_devinfo(dd->pcidev,
+					 "mtrr_add()  WC for PIO bufs failed (%d)\n",
+					 cookie);
+				ret = -EINVAL;
+			}
+		} else {
+			dd->wc_cookie = cookie;
+			dd->wc_base = (unsigned long) pioaddr;
+			dd->wc_len = (unsigned long) piolen;
+		}
+#endif
 	}
 
 	return ret;
@@ -129,7 +147,22 @@ int qib_enable_wc(struct qib_devdata *dd
  */
 void qib_disable_wc(struct qib_devdata *dd)
 {
+#ifdef HAVE_ARCH_PHYS_WC_ADD
 	arch_phys_wc_del(dd->wc_cookie);
+#else
+	if (dd->wc_cookie) {
+		int r;
+
+		r = mtrr_del(dd->wc_cookie, dd->wc_base,
+			     dd->wc_len);
+		if (r < 0)
+			qib_devinfo(dd->pcidev,
+				 "mtrr_del(%lx, %lx, %lx) failed: %d\n",
+				 dd->wc_cookie, dd->wc_base,
+				 dd->wc_len, r);
+		dd->wc_cookie = 0; /* even on failure */
+	}
+#endif
 }
 
 /**
