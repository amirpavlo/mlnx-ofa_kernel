From: Alaa Hleihel <alaa@mellanox.com>
Subject: [PATCH] BACKPORT: drivers/nvme/host/lightnvm.c

Change-Id: I0e48067d0c4d9ca13e09afd327586c1cf6e4db6a
---
 drivers/nvme/host/lightnvm.c | 86 ++++++++++++++++++++++++++++++++++++++++++++
 1 file changed, 86 insertions(+)

--- a/drivers/nvme/host/lightnvm.c
+++ b/drivers/nvme/host/lightnvm.c
@@ -20,14 +20,18 @@
  *
  */
 
+#ifdef HAVE_LIGHTNVM_NVM_DEV
+
 #include "nvme.h"
 
 #include <linux/nvme.h>
 #include <linux/bitops.h>
 #include <linux/lightnvm.h>
 #include <linux/vmalloc.h>
+#ifdef HAVE_NVM_USER_VIO
 #include <linux/sched/sysctl.h>
 #include <uapi/linux/lightnvm.h>
+#endif
 
 enum nvme_nvm_admin_opcode {
 	nvme_nvm_admin_identity		= 0xe2,
@@ -251,6 +255,7 @@ static int init_grps(struct nvm_id *nvm_
 	struct nvme_nvm_id_group *src;
 	struct nvm_id_group *dst;
 
+#ifdef HAVE_LIGHTNVM_NVM_ID_GRP
 	if (nvme_nvm_id->cgrps != 1)
 		return -EINVAL;
 
@@ -293,6 +298,52 @@ static int init_grps(struct nvm_id *nvm_
 		memcpy(dst->lptbl.mlc.pairs, src->lptbl.mlc.pairs,
 					dst->lptbl.mlc.num_pairs);
 	}
+#else /* HAVE_LIGHTNVM_NVM_ID_GRP */
+	int i, end;
+
+	end = min_t(u32, 4, nvm_id->cgrps);
+	for (i = 0; i < end; i++) {
+		src = &nvme_nvm_id->groups[i];
+		dst = &nvm_id->groups[i];
+
+		dst->mtype = src->mtype;
+		dst->fmtype = src->fmtype;
+		dst->num_ch = src->num_ch;
+		dst->num_lun = src->num_lun;
+		dst->num_pln = src->num_pln;
+
+		dst->num_pg = le16_to_cpu(src->num_pg);
+		dst->num_blk = le16_to_cpu(src->num_blk);
+		dst->fpg_sz = le16_to_cpu(src->fpg_sz);
+		dst->csecs = le16_to_cpu(src->csecs);
+		dst->sos = le16_to_cpu(src->sos);
+
+		dst->trdt = le32_to_cpu(src->trdt);
+		dst->trdm = le32_to_cpu(src->trdm);
+		dst->tprt = le32_to_cpu(src->tprt);
+		dst->tprm = le32_to_cpu(src->tprm);
+		dst->tbet = le32_to_cpu(src->tbet);
+		dst->tbem = le32_to_cpu(src->tbem);
+		dst->mpos = le32_to_cpu(src->mpos);
+		dst->mccap = le32_to_cpu(src->mccap);
+
+		dst->cpar = le16_to_cpu(src->cpar);
+
+		if (dst->fmtype == NVM_ID_FMTYPE_MLC) {
+			memcpy(dst->lptbl.id, src->lptbl.id, 8);
+			dst->lptbl.mlc.num_pairs =
+				le16_to_cpu(src->lptbl.mlc.num_pairs);
+
+			if(dst->lptbl.mlc.num_pairs > NVME_NVM_LP_MLC_PAIRS) {
+				pr_err("nvm: number of MLC pairs not supported\n");
+				return -EINVAL;
+			}
+
+			memcpy(dst->lptbl.mlc.pairs, src->lptbl.mlc.pairs,
+			       dst->lptbl.mlc.num_pairs);
+		}
+	}
+#endif /* HAVE_LIGHTNVM_NVM_ID_GRP */
 
 	return 0;
 }
@@ -321,6 +372,9 @@ static int nvme_nvm_identity(struct nvm_
 
 	nvm_id->ver_id = nvme_nvm_id->ver_id;
 	nvm_id->vmnt = nvme_nvm_id->vmnt;
+#ifndef HAVE_LIGHTNVM_NVM_ID_GRP
+	nvm_id->cgrps = nvme_nvm_id->cgrps;
+#endif
 	nvm_id->cap = le32_to_cpu(nvme_nvm_id->cap);
 	nvm_id->dom = le32_to_cpu(nvme_nvm_id->dom);
 	memcpy(&nvm_id->ppaf, &nvme_nvm_id->ppaf,
@@ -371,8 +425,10 @@ static int nvme_nvm_get_l2p_tbl(struct n
 			goto out;
 		}
 
+#ifdef HAVE_NVMM_TYPE_HAS_PART_TO_TGT
 		/* Transform physical address to target address space */
 		nvm_part_to_tgt(nvmdev, entries, cmd_nlb);
+#endif
 
 		if (update_l2p(cmd_slba, cmd_nlb, entries, priv)) {
 			ret = -EINTR;
@@ -392,12 +448,18 @@ static int nvme_nvm_get_bb_tbl(struct nv
 								u8 *blks)
 {
 	struct request_queue *q = nvmdev->q;
+#ifdef HAVE_NVM_GEO
 	struct nvm_geo *geo = &nvmdev->geo;
+#endif
 	struct nvme_ns *ns = q->queuedata;
 	struct nvme_ctrl *ctrl = ns->ctrl;
 	struct nvme_nvm_command c = {};
 	struct nvme_nvm_bb_tbl *bb_tbl;
+#ifdef HAVE_NVM_GEO
 	int nr_blks = geo->blks_per_lun * geo->plane_mode;
+#else
+	int nr_blks = nvmdev->blks_per_lun * nvmdev->plane_mode;
+#endif
 	int tblsz = sizeof(struct nvme_nvm_bb_tbl) + nr_blks;
 	int ret = 0;
 
@@ -438,7 +500,11 @@ static int nvme_nvm_get_bb_tbl(struct nv
 		goto out;
 	}
 
+#ifdef HAVE_NVM_GEO
 	memcpy(blks, bb_tbl->blk, geo->blks_per_lun * geo->plane_mode);
+#else
+	memcpy(blks, bb_tbl->blk, nvmdev->blks_per_lun * nvmdev->plane_mode);
+#endif
 out:
 	kfree(bb_tbl);
 	return ret;
@@ -485,8 +551,12 @@ static void nvme_nvm_end_io(struct reque
 	struct nvm_rq *rqd = rq->end_io_data;
 
 	rqd->ppa_status = le64_to_cpu(nvme_req(rq)->result.u64);
+#ifdef HAVE_NVM_END_IO_1_PARAM
 	rqd->error = nvme_req(rq)->status;
 	nvm_end_io(rqd);
+#else
+	nvm_end_io(rqd, nvme_req(rq)->status);
+#endif
 
 	kfree(nvme_req(rq)->cmd);
 	blk_mq_free_request(rq);
@@ -514,7 +584,15 @@ static int nvme_nvm_submit_io(struct nvm
 	rq->cmd_flags &= ~REQ_FAILFAST_DRIVER;
 
 	if (bio) {
+#ifdef HAVE_BLK_INIT_REQUEST_FROM_BIO
 		blk_init_request_from_bio(rq, bio);
+#else
+		rq->ioprio = bio_prio(bio);
+		rq->__data_len = bio->bi_iter.bi_size;
+		rq->bio = rq->biotail = bio;
+		if (bio_has_data(bio))
+			rq->nr_phys_segments = bio_phys_segments(q, bio);
+#endif
 	} else {
 		rq->ioprio = IOPRIO_PRIO_VALUE(IOPRIO_CLASS_BE, IOPRIO_NORM);
 		rq->__data_len = 0;
@@ -571,6 +649,7 @@ static struct nvm_dev_ops nvme_nvm_dev_o
 	.max_phys_sect		= 64,
 };
 
+#ifdef HAVE_NVM_USER_VIO
 static int nvme_nvm_submit_user_cmd(struct request_queue *q,
 				struct nvme_ns *ns,
 				struct nvme_nvm_command *vcmd,
@@ -781,6 +860,7 @@ int nvme_nvm_ioctl(struct nvme_ns *ns, u
 		return -ENOTTY;
 	}
 }
+#endif /* HAVE_NVM_USER_VIO */
 
 int nvme_nvm_register(struct nvme_ns *ns, char *disk_name, int node)
 {
@@ -820,7 +900,11 @@ static ssize_t nvm_dev_attr_show(struct
 		return 0;
 
 	id = &ndev->identity;
+#ifdef HAVE_LIGHTNVM_NVM_ID_GRP
 	grp = &id->grp;
+#else
+	grp = &id->groups[0];
+#endif
 	attr = &dattr->attr;
 
 	if (strcmp(attr->name, "version") == 0) {
@@ -992,3 +1076,5 @@ int nvme_nvm_ns_supported(struct nvme_ns
 
 	return 0;
 }
+
+#endif /* HAVE_LIGHTNVM_NVM_DEV */
