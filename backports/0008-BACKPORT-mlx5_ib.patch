From: Mohamad Haj Yahia <mohamad@mellanox.com>
Subject: [PATCH] BACKPORT: mlx5_ib

Change-Id: I5487a899d7d8b925d009d60fa3bcc2a213f7aa33
Signed-off-by: Mohamad Haj Yahia <mohamad@mellanox.com>
---
 drivers/infiniband/hw/mlx5/ib_virt.c     |  7 +++
 drivers/infiniband/hw/mlx5/main.c        | 18 ++++++++
 drivers/infiniband/hw/mlx5/main_exp.c    | 76 ++++++++++++++++++++++++++++++++
 drivers/infiniband/hw/mlx5/mlx5_ib_exp.h |  7 +++
 drivers/infiniband/hw/mlx5/mr.c          |  7 +++
 5 files changed, 115 insertions(+)

--- a/drivers/infiniband/hw/mlx5/ib_virt.c
+++ b/drivers/infiniband/hw/mlx5/ib_virt.c
@@ -34,6 +34,7 @@
 #include <linux/mlx5/vport.h>
 #include "mlx5_ib.h"
 
+#ifdef HAVE_LINKSTATE
 static inline u32 mlx_to_net_policy(enum port_state_policy mlx_policy)
 {
 	switch (mlx_policy) {
@@ -47,6 +48,7 @@ static inline u32 mlx_to_net_policy(enum
 		return __IFLA_VF_LINK_STATE_MAX;
 	}
 }
+#endif
 
 int mlx5_ib_get_vf_config(struct ib_device *device, int vf, u8 port,
 			  struct ifla_vf_info *info)
@@ -78,6 +80,7 @@ free:
 	return err;
 }
 
+#ifdef HAVE_LINKSTATE
 static inline enum port_state_policy net_to_mlx_policy(int policy)
 {
 	switch (policy) {
@@ -116,6 +119,7 @@ out:
 	kfree(in);
 	return err;
 }
+#endif
 
 int mlx5_ib_get_vf_stats(struct ib_device *device, int vf,
 			 u8 port, struct ifla_vf_stats *stats)
@@ -148,6 +152,7 @@ ex:
 	return err;
 }
 
+#ifdef HAVE_IFLA_VF_IB_NODE_PORT_GUID
 static int set_vf_node_guid(struct ib_device *device, int vf, u8 port, u64 guid)
 {
 	struct mlx5_ib_dev *dev = to_mdev(device);
@@ -194,3 +199,5 @@ int mlx5_ib_set_vf_guid(struct ib_device
 
 	return -EINVAL;
 }
+
+#endif
--- a/drivers/infiniband/hw/mlx5/main.c
+++ b/drivers/infiniband/hw/mlx5/main.c
@@ -116,13 +116,17 @@ static int mlx5_netdev_event(struct noti
 
 	case NETDEV_UP:
 	case NETDEV_DOWN: {
+#ifdef HAVE_NETDEV_MASTER_UPPER_DEV_GET
 		struct net_device *lag_ndev = mlx5_lag_get_roce_netdev(ibdev->mdev);
+#endif
 		struct net_device *upper = NULL;
 
+#ifdef HAVE_NETDEV_MASTER_UPPER_DEV_GET
 		if (lag_ndev) {
 			upper = netdev_master_upper_dev_get(lag_ndev);
 			dev_put(lag_ndev);
 		}
+#endif
 
 		if ((upper == ndev || (!upper && ndev == ibdev->roce.netdev))
 		    && ibdev->ib_active) {
@@ -1445,12 +1449,19 @@ static int uar_mmap(struct mlx5_ib_dev *
 	unsigned long idx;
 	phys_addr_t pfn, pa;
 	pgprot_t prot;
+#if defined(CONFIG_X86) && !defined(HAVE_PAT_ENABLED_AS_FUNCTION)
+	pgprot_t tmp_prot = __pgprot(0);
+#endif
 
 	switch (cmd) {
 	case MLX5_IB_MMAP_WC_PAGE:
 /* Some architectures don't support WC memory */
 #if defined(CONFIG_X86)
+#ifdef HAVE_PAT_ENABLED_AS_FUNCTION
 		if (!pat_enabled())
+#else
+		if (pgprot_val(pgprot_writecombine(tmp_prot)) == pgprot_val(pgprot_noncached(tmp_prot)))
+#endif
 			return -EPERM;
 #elif !(defined(CONFIG_PPC) || ((defined(CONFIG_ARM) || defined(CONFIG_ARM64)) && defined(CONFIG_MMU)))
 			return -EPERM;
@@ -3364,6 +3375,9 @@ static void *mlx5_ib_add(struct mlx5_cor
 	dev->ib_dev.exp_query_device	= mlx5_ib_exp_query_device;
 	dev->ib_dev.exp_query_mkey      = mlx5_ib_exp_query_mkey;
 	dev->ib_dev.exp_create_qp	= mlx5_ib_exp_create_qp;
+#ifdef HAVE_MM_STRUCT_FREE_AREA_CACHE
+	dev->ib_dev.exp_get_unmapped_area = mlx5_ib_exp_get_unmapped_area;
+#endif
 	dev->ib_dev.resize_cq		= mlx5_ib_resize_cq;
 	dev->ib_dev.destroy_cq		= mlx5_ib_destroy_cq;
 	dev->ib_dev.poll_cq		= mlx5_ib_poll_cq;
@@ -3383,9 +3397,13 @@ static void *mlx5_ib_add(struct mlx5_cor
 	dev->ib_dev.get_dev_fw_str      = get_dev_fw_str;
 	if (mlx5_core_is_pf(mdev)) {
 		dev->ib_dev.get_vf_config	= mlx5_ib_get_vf_config;
+#ifdef HAVE_LINKSTATE
 		dev->ib_dev.set_vf_link_state	= mlx5_ib_set_vf_link_state;
+#endif
 		dev->ib_dev.get_vf_stats	= mlx5_ib_get_vf_stats;
+#ifdef HAVE_IFLA_VF_IB_NODE_PORT_GUID
 		dev->ib_dev.set_vf_guid		= mlx5_ib_set_vf_guid;
+#endif
 	}
 
 	dev->ib_dev.disassociate_ucontext = mlx5_ib_disassociate_ucontext;
--- a/drivers/infiniband/hw/mlx5/main_exp.c
+++ b/drivers/infiniband/hw/mlx5/main_exp.c
@@ -1152,9 +1152,16 @@ int alloc_and_map_wc(struct mlx5_ib_dev
 	u32 uar_index;
 	struct mlx5_ib_vma_private_data *vma_prv;
 	int err;
+#if defined(CONFIG_X86) && !defined(HAVE_PAT_ENABLED_AS_FUNCTION)
+	pgprot_t prot = __pgprot(0);
+#endif
 
 #if defined(CONFIG_X86)
+#ifdef HAVE_PAT_ENABLED_AS_FUNCTION
 	if (!pat_enabled()) {
+#else
+	if (pgprot_val(pgprot_writecombine(prot)) == pgprot_val(pgprot_noncached(prot))) {
+#endif
 		mlx5_ib_dbg(dev, "write combine not available\n");
 		return -EPERM;
 	}
@@ -1225,3 +1232,72 @@ int mlx5_get_roce_gid_type(struct mlx5_i
 
 	return ret;
 }
+
+#ifdef HAVE_MM_STRUCT_FREE_AREA_CACHE
+static int get_command(unsigned long offset)
+{
+	int cmd = (offset >> MLX5_IB_MMAP_CMD_SHIFT) & MLX5_IB_MMAP_CMD_MASK;
+
+	return (cmd == MLX5_IB_EXP_MMAP_CORE_CLOCK) ? MLX5_IB_MMAP_CORE_CLOCK :
+		cmd;
+}
+
+unsigned long mlx5_ib_exp_get_unmapped_area(struct file *file,
+					    unsigned long addr,
+					    unsigned long len,
+					    unsigned long pgoff,
+					    unsigned long flags)
+{
+	struct mm_struct *mm;
+	struct vm_area_struct *vma;
+	unsigned long start_addr;
+	unsigned long order;
+	unsigned long command;
+
+	mm = current->mm;
+	if (addr)
+		return current->mm->get_unmapped_area(file, addr, len,
+						      pgoff, flags);
+	command = get_command(pgoff);
+	if (command == MLX5_IB_MMAP_REGULAR_PAGE ||
+	    command == MLX5_IB_MMAP_WC_PAGE ||
+	    command == MLX5_IB_MMAP_NC_PAGE ||
+	    command == MLX5_IB_MMAP_MAP_DC_INFO_PAGE ||
+	    command == MLX5_IB_EXP_ALLOC_N_MMAP_WC ||
+	    command == MLX5_IB_MMAP_CORE_CLOCK)
+		return current->mm->get_unmapped_area(file, addr, len,
+						      pgoff, flags);
+
+	if (command != MLX5_IB_MMAP_GET_CONTIGUOUS_PAGES &&
+	    command != MLX5_IB_EXP_MMAP_GET_CONTIGUOUS_PAGES_DEV_NUMA &&
+	    command != MLX5_IB_EXP_MMAP_GET_CONTIGUOUS_PAGES_CPU_NUMA) {
+		pr_warn("get_unmapped_area unsupported command %ld\n", command);
+		return -EINVAL;
+	}
+
+	order = get_pg_order(pgoff);
+
+	/*
+	 * code is based on the huge-pages get_unmapped_area code
+	 */
+	start_addr = mm->free_area_cache;
+	if (len <= mm->cached_hole_size)
+		start_addr = TASK_UNMAPPED_BASE;
+full_search:
+	addr = ALIGN(start_addr, 1 << order);
+
+	for (vma = find_vma(mm, addr); ; vma = vma->vm_next) {
+		if (addr > TASK_SIZE - len) {
+			if (start_addr != TASK_UNMAPPED_BASE) {
+				start_addr = TASK_UNMAPPED_BASE;
+				goto full_search;
+			}
+			return -ENOMEM;
+		}
+
+		if (!vma || addr + len <= vma->vm_start)
+			return addr;
+		addr = ALIGN(vma->vm_end, 1 << order);
+	}
+}
+#endif
--- a/drivers/infiniband/hw/mlx5/mlx5_ib_exp.h
+++ b/drivers/infiniband/hw/mlx5/mlx5_ib_exp.h
@@ -253,5 +253,12 @@ int mlx5_ib_exp_get_cmd_data(struct mlx5
 int mlx5_get_roce_gid_type(struct mlx5_ib_dev *dev, u8 port,
 			   int index, int *gid_type);
 
+#ifdef HAVE_MM_STRUCT_FREE_AREA_CACHE
+unsigned long mlx5_ib_exp_get_unmapped_area(struct file *file,
+					    unsigned long addr,
+					    unsigned long len,
+					    unsigned long pgoff,
+					    unsigned long flags);
+#endif
 
 #endif
--- a/drivers/infiniband/hw/mlx5/mr.c
+++ b/drivers/infiniband/hw/mlx5/mr.c
@@ -38,6 +38,9 @@
 #include <linux/delay.h>
 #include <linux/device.h>
 #include <linux/sysfs.h>
+#ifndef ARCH_KMALLOC_MINALIGN
+#include <linux/crypto.h>
+#endif
 #include <rdma/ib_umem.h>
 #include <rdma/ib_umem_odp.h>
 #include <rdma/ib_verbs.h>
@@ -1360,7 +1363,11 @@ mlx5_alloc_priv_descs(struct ib_device *
 	int add_size;
 	int ret;
 
+#ifdef ARCH_KMALLOC_MINALIGN
 	add_size = max_t(int, MLX5_UMR_ALIGN - ARCH_KMALLOC_MINALIGN, 0);
+#else
+	add_size = max_t(int, MLX5_UMR_ALIGN - CRYPTO_MINALIGN, 0);
+#endif
 
 	mr->descs_alloc = kzalloc(size + add_size, GFP_KERNEL);
 	if (!mr->descs_alloc)
