From: Israel Rukshin <israelr@mellanox.com>
Subject: [PATCH] BACKPORT: ib_isert

Change-Id: I534bf4501a3199989b8d6ac14aa162d34a4875bc
Signed-off-by: Israel Rukshin <israelr@mellanox.com>
---
 drivers/infiniband/ulp/isert/ib_isert.c  |  177 +++++++++++++++++++++++++++++-
 include/target/iscsi/iscsi_target_core.h |   12 ++
 include/target/iscsi/iscsi_transport.h   |    2 +
 3 files changed, 189 insertions(+), 2 deletions(-)

--- a/drivers/infiniband/ulp/isert/ib_isert.c
+++ b/drivers/infiniband/ulp/isert/ib_isert.c
@@ -64,11 +64,14 @@ static void isert_login_send_done(struct
 static inline bool
 isert_prot_cmd(struct isert_conn *conn, struct se_cmd *cmd)
 {
+#ifdef HAVE_ISCSIT_TRANSPORT_HAS_GET_SUP_PROT_OPS
 	return (conn->pi_support &&
 		cmd->prot_op != TARGET_PROT_NORMAL);
+#else
+	return false;
+#endif
 }
 
-
 static void
 isert_qp_event_callback(struct ib_event *e, void *context)
 {
@@ -499,11 +502,20 @@ static int
 isert_connect_request(struct rdma_cm_id *cma_id, struct rdma_cm_event *event)
 {
 	struct isert_np *isert_np = cma_id->context;
+#if defined(CONFIG_COMPAT_RHEL_7_1)\
+	|| defined(CONFIG_COMPAT_SLES_12)\
+	|| defined(CONFIG_COMPAT_FBK_16)\
+	|| (LINUX_VERSION_CODE >= KERNEL_VERSION(3,15,0))
 	struct iscsi_np *np = isert_np->np;
+#endif
 	struct isert_conn *isert_conn;
 	struct isert_device *device;
 	int ret = 0;
 
+#if defined(CONFIG_COMPAT_RHEL_7_1)\
+	|| defined(CONFIG_COMPAT_SLES_12)\
+	|| defined(CONFIG_COMPAT_FBK_16)\
+	|| (LINUX_VERSION_CODE >= KERNEL_VERSION(3,15,0))
 	spin_lock_bh(&np->np_thread_lock);
 	if (!np->enabled) {
 		spin_unlock_bh(&np->np_thread_lock);
@@ -511,6 +523,7 @@ isert_connect_request(struct rdma_cm_id
 		return rdma_reject(cma_id, NULL, 0);
 	}
 	spin_unlock_bh(&np->np_thread_lock);
+#endif
 
 	isert_dbg("cma_id: %p, portal: %p\n",
 		 cma_id, cma_id->context);
@@ -1124,8 +1137,15 @@ isert_handle_scsi_cmd(struct isert_conn
 	unsol_data = cmd->unsolicited_data;
 	data_len = cmd->se_cmd.data_length;
 
+#if !defined HAVE_TARGET_SUPPORT_COMPARE_AND_WRITE ||\
+     defined HAVE_SE_CMD_TRANSPORT_COMPLETE_CALLBACK_HAS_THREE_PARAM
 	if (imm_data && imm_data_len == data_len)
 		cmd->se_cmd.se_cmd_flags |= SCF_PASSTHROUGH_SG_TO_MEM_NOALLOC;
+#else
+	if (imm_data && imm_data_len == data_len &&
+            !(cmd->se_cmd.se_cmd_flags & SCF_COMPARE_AND_WRITE))
+		cmd->se_cmd.se_cmd_flags |= SCF_PASSTHROUGH_SG_TO_MEM_NOALLOC;
+#endif
 	rc = iscsit_process_scsi_cmd(conn, cmd, hdr);
 	if (rc < 0) {
 		return 0;
@@ -1137,7 +1157,13 @@ isert_handle_scsi_cmd(struct isert_conn
 	if (!imm_data)
 		return 0;
 
+#if !defined HAVE_TARGET_SUPPORT_COMPARE_AND_WRITE ||\
+    defined HAVE_SE_CMD_TRANSPORT_COMPLETE_CALLBACK_HAS_THREE_PARAM
 	if (imm_data_len != data_len) {
+#else
+	if (imm_data_len != data_len ||
+            (cmd->se_cmd.se_cmd_flags & SCF_COMPARE_AND_WRITE)) {
+#endif
 		sg_nents = max(1UL, DIV_ROUND_UP(imm_data_len, PAGE_SIZE));
 		sg_copy_from_buffer(cmd->se_cmd.t_data_sg, sg_nents,
 				    &rx_desc->data[0], imm_data_len);
@@ -1167,7 +1193,11 @@ sequence_cmd:
 	if (!rc && dump_payload == false && unsol_data)
 		iscsit_set_unsoliticed_dataout(cmd);
 	else if (dump_payload && imm_data)
+#ifdef HAVE_TARGET_PUT_SESS_CMD_HAS_1_PARAM
 		target_put_sess_cmd(&cmd->se_cmd);
+#else
+		target_put_sess_cmd(conn->sess->se_sess, &cmd->se_cmd);
+#endif
 
 	return 0;
 }
@@ -1346,10 +1376,14 @@ isert_rx_opcode(struct isert_conn *isert
 		ret = iscsit_handle_logout_cmd(conn, cmd, (unsigned char *)hdr);
 		break;
 	case ISCSI_OP_TEXT:
+#ifdef HAVE_ISCSIT_FIND_CMD_FROM_ITT
 		if (be32_to_cpu(hdr->ttt) != 0xFFFFFFFF)
 			cmd = iscsit_find_cmd_from_itt(conn, hdr->itt);
 		else
 			cmd = isert_allocate_cmd(conn, rx_desc);
+#else
+		cmd = isert_allocate_cmd(conn, rx_desc);
+#endif
 
 		if (!cmd)
 			break;
@@ -1467,6 +1501,34 @@ isert_login_recv_done(struct ib_cq *cq,
 				ISER_RX_PAYLOAD_SIZE, DMA_FROM_DEVICE);
 }
 
+#ifndef HAVE_TARGET_FABRIC_HAS_TARGET_REVERSE_DMA_DIRECTION
+/*
+ * The LIO target core uses DMA_TO_DEVICE to mean that data is going
+ * to the target (eg handling a WRITE) and DMA_FROM_DEVICE to mean
+ * that data is coming from the target (eg handling a READ).  However,
+ * this is just the opposite of what we have to tell the DMA mapping
+ * layer -- eg when handling a READ, the HBA will have to DMA the data
+ * out of memory so it can send it to the initiator, which means we
+ * need to use DMA_TO_DEVICE when we map the data.
+ */
+static inline enum dma_data_direction
+target_reverse_dma_direction(struct se_cmd *se_cmd)
+{
+	if (se_cmd->se_cmd_flags & SCF_BIDI)
+		return DMA_BIDIRECTIONAL;
+
+	switch (se_cmd->data_direction) {
+		case DMA_TO_DEVICE:
+			return DMA_FROM_DEVICE;
+		case DMA_FROM_DEVICE:
+			return DMA_TO_DEVICE;
+		case DMA_NONE:
+		default:
+			return DMA_NONE;
+	}
+}
+#endif
+
 static void
 isert_rdma_rw_ctx_destroy(struct isert_cmd *cmd, struct isert_conn *conn)
 {
@@ -1476,6 +1538,7 @@ isert_rdma_rw_ctx_destroy(struct isert_c
 	if (!cmd->rw.nr_ops)
 		return;
 
+#ifdef HAVE_ISCSIT_TRANSPORT_HAS_GET_SUP_PROT_OPS
 	if (isert_prot_cmd(conn, se_cmd)) {
 		rdma_rw_ctx_destroy_signature(&cmd->rw, conn->qp,
 				conn->cm_id->port_num, se_cmd->t_data_sg,
@@ -1485,6 +1548,10 @@ isert_rdma_rw_ctx_destroy(struct isert_c
 		rdma_rw_ctx_destroy(&cmd->rw, conn->qp, conn->cm_id->port_num,
 				se_cmd->t_data_sg, se_cmd->t_data_nents, dir);
 	}
+#else
+	rdma_rw_ctx_destroy(&cmd->rw, conn->qp, conn->cm_id->port_num,
+			se_cmd->t_data_sg, se_cmd->t_data_nents, dir);
+#endif
 
 	cmd->rw.nr_ops = 0;
 }
@@ -1517,8 +1584,11 @@ isert_put_cmd(struct isert_cmd *isert_cm
 			if (comp_err &&
 			    cmd->se_cmd.t_state == TRANSPORT_WRITE_PENDING) {
 				struct se_cmd *se_cmd = &cmd->se_cmd;
-
+#ifdef HAVE_TARGET_PUT_SESS_CMD_HAS_1_PARAM
 				target_put_sess_cmd(se_cmd);
+#else
+				target_put_sess_cmd(se_cmd->se_sess, se_cmd);
+#endif
 			}
 		}
 
@@ -1592,6 +1662,7 @@ isert_completion_put(struct iser_tx_desc
 	isert_put_cmd(isert_cmd, comp_err);
 }
 
+#ifdef HAVE_ISCSIT_TRANSPORT_HAS_GET_SUP_PROT_OPS
 static int
 isert_check_pi_status(struct se_cmd *se_cmd, struct ib_mr *sig_mr)
 {
@@ -1635,6 +1706,7 @@ isert_check_pi_status(struct se_cmd *se_
 fail_mr_status:
 	return ret;
 }
+#endif
 
 static void
 isert_rdma_write_done(struct ib_cq *cq, struct ib_wc *wc)
@@ -1643,8 +1715,10 @@ isert_rdma_write_done(struct ib_cq *cq,
 	struct isert_device *device = isert_conn->device;
 	struct iser_tx_desc *desc = cqe_to_tx_desc(wc->wr_cqe);
 	struct isert_cmd *isert_cmd = tx_desc_to_cmd(desc);
+#ifdef HAVE_ISCSIT_TRANSPORT_HAS_GET_SUP_PROT_OPS
 	struct se_cmd *cmd = &isert_cmd->iscsi_cmd->se_cmd;
 	int ret = 0;
+#endif
 
 	if (unlikely(wc->status != IB_WC_SUCCESS)) {
 		isert_print_wc(wc, "rdma write");
@@ -1656,6 +1730,7 @@ isert_rdma_write_done(struct ib_cq *cq,
 
 	isert_dbg("Cmd %p\n", isert_cmd);
 
+#ifdef HAVE_ISCSIT_TRANSPORT_HAS_GET_SUP_PROT_OPS
 	ret = isert_check_pi_status(cmd, isert_cmd->rw.sig->sig_mr);
 	isert_rdma_rw_ctx_destroy(isert_cmd, isert_conn);
 
@@ -1663,6 +1738,10 @@ isert_rdma_write_done(struct ib_cq *cq,
 		transport_send_check_condition_and_sense(cmd, cmd->pi_err, 0);
 	else
 		isert_put_response(isert_conn->conn, isert_cmd->iscsi_cmd);
+#else
+	isert_rdma_rw_ctx_destroy(isert_cmd, isert_conn);
+	isert_put_response(isert_conn->conn, isert_cmd->iscsi_cmd);
+#endif
 }
 
 static void
@@ -1688,8 +1767,11 @@ isert_rdma_read_done(struct ib_cq *cq, s
 
 	iscsit_stop_dataout_timer(cmd);
 
+#ifdef HAVE_ISCSIT_TRANSPORT_HAS_GET_SUP_PROT_OPS
 	if (isert_prot_cmd(isert_conn, se_cmd))
 		ret = isert_check_pi_status(se_cmd, isert_cmd->rw.sig->sig_mr);
+#endif
+
 	isert_rdma_rw_ctx_destroy(isert_cmd, isert_conn);
 	cmd->write_data_done = 0;
 
@@ -1700,9 +1782,15 @@ isert_rdma_read_done(struct ib_cq *cq, s
 	spin_unlock_bh(&cmd->istate_lock);
 
 	if (ret) {
+#ifdef HAVE_TARGET_PUT_SESS_CMD_HAS_1_PARAM
 		target_put_sess_cmd(se_cmd);
+#else
+		target_put_sess_cmd(se_cmd->se_sess, se_cmd);
+#endif
+#ifdef HAVE_ISCSIT_TRANSPORT_HAS_GET_SUP_PROT_OPS
 		transport_send_check_condition_and_sense(se_cmd,
 							 se_cmd->pi_err, 0);
+#endif
 	} else {
 		target_execute_cmd(se_cmd);
 	}
@@ -1877,25 +1965,31 @@ isert_aborted_task(struct iscsi_conn *co
 	isert_rdma_rw_ctx_destroy(isert_cmd, isert_conn);
 }
 
+#ifdef HAVE_ISCSIT_TRANSPORT_HAS_GET_SUP_PROT_OPS
 static enum target_prot_op
 isert_get_sup_prot_ops(struct iscsi_conn *conn)
 {
 	struct isert_conn *isert_conn = conn->context;
 	struct isert_device *device = isert_conn->device;
 
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(3,19,0))
 	if (conn->tpg->tpg_attrib.t10_pi) {
+#endif
 		if (device->pi_capable) {
 			isert_info("conn %p PI offload enabled\n", isert_conn);
 			isert_conn->pi_support = true;
 			return TARGET_PROT_ALL;
 		}
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(3,19,0))
 	}
+#endif
 
 	isert_info("conn %p PI offload disabled\n", isert_conn);
 	isert_conn->pi_support = false;
 
 	return TARGET_PROT_NORMAL;
 }
+#endif
 
 static int
 isert_put_nopin(struct iscsi_cmd *cmd, struct iscsi_conn *conn,
@@ -2031,6 +2125,7 @@ isert_put_text_rsp(struct iscsi_cmd *cmd
 	return isert_post_response(isert_conn, isert_cmd);
 }
 
+#ifdef HAVE_SE_CMD_HAS_PROT_CHECKS
 static inline void
 isert_set_dif_domain(struct se_cmd *se_cmd, struct ib_sig_attrs *sig_attrs,
 		     struct ib_sig_domain *domain)
@@ -2084,6 +2179,7 @@ isert_set_sig_attrs(struct se_cmd *se_cm
 	       (se_cmd->prot_checks & TARGET_DIF_CHECK_REFTAG ? 0x0f : 0);
 	return 0;
 }
+#endif
 
 static int
 isert_rdma_rw_ctx_post(struct isert_cmd *cmd, struct isert_conn *conn,
@@ -2106,6 +2202,7 @@ isert_rdma_rw_ctx_post(struct isert_cmd
 		offset = 0;
 	}
 
+#ifdef HAVE_SE_CMD_HAS_PROT_CHECKS
 	if (isert_prot_cmd(conn, se_cmd)) {
 		struct ib_sig_attrs sig_attrs;
 
@@ -2123,6 +2220,12 @@ isert_rdma_rw_ctx_post(struct isert_cmd
 				se_cmd->t_data_sg, se_cmd->t_data_nents,
 				offset, addr, rkey, dir);
 	}
+#else
+	ret = rdma_rw_ctx_init(&cmd->rw, conn->qp, port_num,
+			se_cmd->t_data_sg, se_cmd->t_data_nents,
+			offset, addr, rkey, dir);
+#endif
+
 	if (ret < 0) {
 		isert_err("Cmd: %p failed to prepare RDMA res\n", cmd);
 		return ret;
@@ -2410,11 +2513,47 @@ isert_set_conn_info(struct iscsi_np *np,
 {
 	struct rdma_cm_id *cm_id = isert_conn->cm_id;
 	struct rdma_route *cm_route = &cm_id->route;
+#ifndef HAVE_ISCSI_CONN_LOGIN_SOCKADDR
+	struct sockaddr_in *sock_in;
+	struct sockaddr_in6 *sock_in6;
+#endif
 
 	conn->login_family = np->np_sockaddr.ss_family;
 
+#ifdef HAVE_ISCSI_CONN_LOGIN_SOCKADDR
 	conn->login_sockaddr = cm_route->addr.dst_addr;
 	conn->local_sockaddr = cm_route->addr.src_addr;
+#else
+	if (np->np_sockaddr.ss_family == AF_INET6) {
+		sock_in6 = (struct sockaddr_in6 *)&cm_route->addr.dst_addr;
+		snprintf(conn->login_ip, sizeof(conn->login_ip), "%pI6c",
+		         &sock_in6->sin6_addr.in6_u);
+		conn->login_port = ntohs(sock_in6->sin6_port);
+
+		sock_in6 = (struct sockaddr_in6 *)&cm_route->addr.src_addr;
+#ifdef HAVE_ISCSI_CONN_LOCAL_SOCKADDR
+		memcpy(&conn->local_sockaddr , &sock_in6, sizeof(sock_in6));
+#else
+		snprintf(conn->local_ip, sizeof(conn->local_ip), "%pI6c",
+		         &sock_in6->sin6_addr.in6_u);
+		conn->local_port = ntohs(sock_in6->sin6_port);
+#endif //HAVE_ISCSI_CONN_LOCAL_SOCKADDR
+	} else {
+		sock_in = (struct sockaddr_in *)&cm_route->addr.dst_addr;
+		sprintf(conn->login_ip, "%pI4",
+		        &sock_in->sin_addr.s_addr);
+		conn->login_port = ntohs(sock_in->sin_port);
+
+		sock_in = (struct sockaddr_in *)&cm_route->addr.src_addr;
+#ifdef HAVE_ISCSI_CONN_LOCAL_SOCKADDR
+		memcpy(&conn->local_sockaddr , &sock_in, sizeof(sock_in));
+#else
+		sprintf(conn->local_ip, "%pI4",
+		        &sock_in->sin_addr.s_addr);
+		conn->local_port = ntohs(sock_in->sin_port);
+#endif //HAVE_ISCSI_CONN_LOCAL_SOCKADDR
+	}
+#endif //HAVE_ISCSI_CONN_LOGIN_SOCKADDR
 }
 
 static int
@@ -2583,6 +2722,7 @@ isert_put_unsol_pending_cmds(struct iscs
 	}
 }
 
+#if defined(CONFIG_COMPAT_ISCSIT_WAIT_CONN)
 static void isert_wait_conn(struct iscsi_conn *conn)
 {
 	struct isert_conn *isert_conn = conn->context;
@@ -2600,15 +2740,39 @@ static void isert_wait_conn(struct iscsi
 
 	queue_work(isert_release_wq, &isert_conn->release_work);
 }
+#endif
 
 static void isert_free_conn(struct iscsi_conn *conn)
 {
 	struct isert_conn *isert_conn = conn->context;
 
+#if !defined(CONFIG_COMPAT_ISCSIT_WAIT_CONN)
+	mutex_lock(&isert_conn->mutex);
+	/*
+	 * Only wait for conn_wait_comp_err if the isert_conn made it
+	 * into rdma connect.
+	 */
+	if (isert_conn->state == ISER_CONN_INIT) {
+		mutex_unlock(&isert_conn->mutex);
+		goto out;
+	}
+	isert_conn_terminate(isert_conn);
+	mutex_unlock(&isert_conn->mutex);
+
+	ib_drain_qp(isert_conn->qp);
+	isert_put_unsol_pending_cmds(conn);
+	isert_wait4cmds(conn);
+	isert_wait4logout(isert_conn);
+
+	queue_work(isert_release_wq, &isert_conn->release_work);
+out:
+#else
 	ib_drain_qp(isert_conn->qp);
+#endif
 	isert_put_conn(isert_conn);
 }
 
+#ifdef HAVE_ISCSIT_TRANSPORT_ISCSIT_GET_RX_PDU
 static void isert_get_rx_pdu(struct iscsi_conn *conn)
 {
 	struct completion comp;
@@ -2617,17 +2781,22 @@ static void isert_get_rx_pdu(struct iscs
 
 	wait_for_completion_interruptible(&comp);
 }
+#endif
 
 static struct iscsit_transport iser_target_transport = {
 	.name			= "IB/iSER",
 	.transport_type		= ISCSI_INFINIBAND,
+#ifdef HAVE_ISCSIT_TRANSPORT_RDMA_SHUTDOWN
 	.rdma_shutdown		= true,
+#endif
 	.priv_size		= sizeof(struct isert_cmd),
 	.owner			= THIS_MODULE,
 	.iscsit_setup_np	= isert_setup_np,
 	.iscsit_accept_np	= isert_accept_np,
 	.iscsit_free_np		= isert_free_np,
+#if defined(CONFIG_COMPAT_ISCSIT_WAIT_CONN)
 	.iscsit_wait_conn	= isert_wait_conn,
+#endif
 	.iscsit_free_conn	= isert_free_conn,
 	.iscsit_get_login_rx	= isert_get_login_rx,
 	.iscsit_put_login_tx	= isert_put_login_tx,
@@ -2637,8 +2806,12 @@ static struct iscsit_transport iser_targ
 	.iscsit_queue_data_in	= isert_put_datain,
 	.iscsit_queue_status	= isert_put_response,
 	.iscsit_aborted_task	= isert_aborted_task,
+#ifdef HAVE_ISCSIT_TRANSPORT_ISCSIT_GET_RX_PDU
 	.iscsit_get_rx_pdu	= isert_get_rx_pdu,
+#endif
+#ifdef HAVE_ISCSIT_TRANSPORT_HAS_GET_SUP_PROT_OPS
 	.iscsit_get_sup_prot_ops = isert_get_sup_prot_ops,
+#endif
 };
 
 static int __init isert_init(void)
--- a/include/target/iscsi/iscsi_target_core.h
+++ b/include/target/iscsi/iscsi_target_core.h
@@ -775,7 +775,9 @@ struct iscsi_tpg_attrib {
 	u32			prod_mode_write_protect;
 	u32			demo_mode_discovery;
 	u32			default_erl;
+#ifdef HAVE_ISCSIT_TRANSPORT_HAS_GET_SUP_PROT_OPS
 	u8			t10_pi;
+#endif
 	struct iscsi_portal_group *tpg;
 };
 
@@ -784,7 +786,12 @@ struct iscsi_np {
 	int			np_ip_proto;
 	int			np_sock_type;
 	enum np_thread_state_table np_thread_state;
+#if defined(CONFIG_COMPAT_RHEL_7_1)\
+	|| defined(CONFIG_COMPAT_SLES_12)\
+	|| defined(CONFIG_COMPAT_FBK_16)\
+	|| (LINUX_VERSION_CODE >= KERNEL_VERSION(3,15,0))
 	bool                    enabled;
+#endif
 	enum iscsi_timer_flags_table np_login_timer_flags;
 	u32			np_exports;
 	enum np_flags_table	np_flags;
@@ -799,6 +806,11 @@ struct iscsi_np {
 	void			*np_context;
 	struct iscsit_transport *np_transport;
 	struct list_head	np_list;
+#if defined(CONFIG_COMPAT_SLES_12_0) ||\
+	((LINUX_VERSION_CODE >= KERNEL_VERSION(3,15,0)) &&\
+	(LINUX_VERSION_CODE < KERNEL_VERSION(3,19,0)))
+	struct iscsi_tpg_np     *tpg_np;
+#endif
 } ____cacheline_aligned;
 
 struct iscsi_tpg_np {
--- a/include/target/iscsi/iscsi_transport.h
+++ b/include/target/iscsi/iscsi_transport.h
@@ -21,7 +21,9 @@ struct iscsit_transport {
 	int (*iscsit_setup_np)(struct iscsi_np *, struct __kernel_sockaddr_storage *);
 	int (*iscsit_accept_np)(struct iscsi_np *, struct iscsi_conn *);
 	void (*iscsit_free_np)(struct iscsi_np *);
+#if defined(CONFIG_COMPAT_ISCSIT_WAIT_CONN)
 	void (*iscsit_wait_conn)(struct iscsi_conn *);
+#endif
 	void (*iscsit_free_conn)(struct iscsi_conn *);
 	int (*iscsit_get_login_rx)(struct iscsi_conn *, struct iscsi_login *);
 	int (*iscsit_put_login_tx)(struct iscsi_conn *, struct iscsi_login *, u32);
